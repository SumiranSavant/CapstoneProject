{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - The Battle of the Neighborhoods (Week 2)\n",
    "### Applied Data Science Capstone by IBM/Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction: Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Delhi is the capital of the worlds most populated country, India with a population of 29.596 million.\n",
    "here you discuss the business problem and who would be interested in this project.\n",
    "\n",
    "\"Would you recommend a location in New Delhi to open a new cinema?\"\n",
    "My boss, the stakeholder wants to open a new cinema as company's new business.\n",
    "\n",
    "He explains that watching movie is a part of whole afternoon or night activities. Cinemas should have many restaurants and shopping places nearby. Transportation is also an important factor. Customer can walk into cinema within 5 minutes from public transport facilities is appropriate.\n",
    "\n",
    "He wants me to concentrate on selection of cinema location according to its nearby environment. Cinema facility and rental price is not the concern. He lists out his top 10 favorite cinemas in New Delhi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on definition of our problem, factors that will influence our decission are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li> number of existing cinemas in the neighborhood </li>\n",
    "    <li> number of and distance to cinemas in the neighborhood, if any </li>\n",
    "<li> distance of neighborhood from city center </li>\n",
    "   \n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data where you describe the data that will be used to solve the problem and the source of the data.\n",
    "\n",
    "According to the question, following data are required.\n",
    "\n",
    "1. Geographic coordinate of public hospitals in New Delhi\n",
    "I need to compare 5 possible locations with current hospitals in New Delhi. Therefore, I need to find a list of public hospitals in New Delhi and their geographic coordinates. Luckily, I can find the list and coordinates from the website https://en.wikipedia.org/wiki/List_of_cinemas_in_Delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-24 15:42:39--  https://en.wikipedia.org/wiki/List_of_cinemas_in_Delhi\n",
      "Resolving en.wikipedia.org (en.wikipedia.org)... 208.80.154.224, 2620:0:861:ed1a::1\n",
      "Connecting to en.wikipedia.org (en.wikipedia.org)|208.80.154.224|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘del_cine_list.json’\n",
      "\n",
      "del_cine_list.json      [ <=>                ]  79.40K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2019-08-24 15:42:39 (1023 KB/s) - ‘del_cine_list.json’ saved [81310]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the hospital list\n",
    "!wget -O del_cine_list.json https://en.wikipedia.org/wiki/List_of_cinemas_in_Delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-de8f8b509cb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcinemas_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'del_cine_list.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcinemas_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcinemas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "cinemas_json = None\n",
    "with open('del_cine_list.json', 'r', encoding='utf-8') as f:\n",
    "    cinemas_json = json.load(f)\n",
    "    \n",
    "cinemas = []\n",
    "for data in cinemas_json['data']:    \n",
    "    cinemas.append({\n",
    "        'Name': data['name'],\n",
    "        'Address': data['address'],\n",
    "        'Latitude': data['lat'],\n",
    "        'Longitude': data['lon']\n",
    "    })\n",
    "df_cinemas = pd.DataFrame(cinemas, columns=['Name','Address','Latitude','Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cinemas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-46ce9232e20e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are {} cinemas in New Delhi'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cinemas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cinemas' is not defined"
     ]
    }
   ],
   "source": [
    "print('There are {} cinemas in New Delhi'.format(len(df_cinemas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cinemas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Geographic coordinates of 5 possible cinema addresses\n",
    "Geographic coordinates of 5 possible cinemas are required and I can use Google Map API to find this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "possible_locations = [\n",
    "    { 'Location': 'L1', 'Address': 'Community Centre, Saket'},\n",
    "    { 'Location': 'L2', 'Address': 'Pacific Mall, Subhash Nagar'},\n",
    "    { 'Location': 'L3', 'Address': 'DLF Place, Saket'},\n",
    "    { 'Location': 'L4', 'Address': 'Ambience Mall, Vasant Kunj'},\n",
    "    { 'Location': 'L5', 'Address': 'City Centre, Janakpuri'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googlemaps\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/92/5c4858d6fcf4990196acc187f2479d6ac0c43aec80eb7b25463f0262db38/googlemaps-3.0.2-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0,>=2.20.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from googlemaps) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->googlemaps) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->googlemaps) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2019.6.16)\n",
      "Installing collected packages: googlemaps\n",
      "Successfully installed googlemaps-3.0.2\n"
     ]
    }
   ],
   "source": [
    "#install the google map api client library\n",
    "!pip install -U googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'google_map_act.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-075efa74f0fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgoogle_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google_map_act.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgoogle_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mGOOGLE_MAP_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle_act\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'google_map_act.json'"
     ]
    }
   ],
   "source": [
    "google_act = None\n",
    "with open('google_map_act.json', 'r') as f:\n",
    "    google_act = json.load(f)\n",
    "    \n",
    "GOOGLE_MAP_API_KEY = google_act['api_key']    \n",
    "\n",
    "import googlemaps\n",
    "gmaps = googlemaps.Client(key=GOOGLE_MAP_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLatLng(address):\n",
    "    latlnt = gmaps.geocode('{}, New Delhi'.format(address))\n",
    "    return (latlnt[0]['geometry']['location']['lat'], latlnt[0]['geometry']['location']['lng'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe of 5 target locations with geographic coordinates information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in possible_locations:        \n",
    "    (lat, lng) = getLatLng(loc['Address'])\n",
    "    loc['Latitude'] = lat\n",
    "    loc['Longitude'] = lng\n",
    "    \n",
    "df_possible_locations = pd.DataFrame(possible_locations, columns=['Location', 'Address', 'Latitude', 'Longitude'])\n",
    "df_possible_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Favorite cinema list of stakeholder\n",
    "The favorite cinema list of stakeholder is an important information that I can use it as profile to select the best location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "boss_favorite = [\n",
    "    {'Name': 'PVR Saket', 'Rating': 4.5},\n",
    "    {'Name': 'PVR Select City Walk', 'Rating': 4.5},\n",
    "    {'Name': 'Wave Cinemas Raja Garden', 'Rating': 4.3},\n",
    "    {'Name': 'Cinemax Subhash Nagar', 'Rating': 3.4},\n",
    "    {'Name': 'AMC Pacific Place', 'Rating': 2.3},\n",
    "    {'Name': 'PVR Naraina', 'Rating': 1.5},\n",
    "]\n",
    "\n",
    "df_boss_favorite = pd.DataFrame(boss_favorite, columns=['Name','Rating'])\n",
    "df_boss_favorite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Eating, Shopping and Public transportation facility around cinema\n",
    "The recommended cinema location needs to have many eating and shopping venues nearby. Convenient public transport is also required.\n",
    "These data can be found by using FourSquare API to find these venues around the location. The radius of exploration distance is set to 500 meters, which is about 5 minutes walking distance.\n",
    "\n",
    "Following type of venue category will be used to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_categories = {\n",
    "    'Food': '4d4b7105d754a06374d81259',\n",
    "    'Shop & Service': '4d4b7105d754a06378d81259',\n",
    "    'Bus Stop': '52f2ab2ebcbc57f1066b8b4f',\n",
    "    'Metro Station': '4bf58dd8d48988d1fd931735',\n",
    "    'Nightlife Spot': '4d4b7105d754a06376d81259',\n",
    "    'Arts & Entertainment': '4d4b7104d754a06370d81259'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Food, Shop & Service, Bus Stop, Metro Station, Nightlife Spot, Arts & Entertainment'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join([ cat for cat in fs_categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cinemas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f83d6b3051a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcinema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cinemas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cinemas' is not defined"
     ]
    }
   ],
   "source": [
    "cinema = df_cinemas.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cinema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-eb69a38630a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Use the first cinema \"{}\" in the list as example to explore venues nearyby'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcinema\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cinema' is not defined"
     ]
    }
   ],
   "source": [
    "print('Use the first cinema \"{}\" in the list as example to explore venues nearyby'.format(cinema['Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting foursquare\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/fc/825326248f9caf7c19a58dede1b7f1604573e998dd6f6003cba1701215db/foursquare-1%212019.2.16.tar.gz\n",
      "Requirement already satisfied: requests>=2.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from foursquare) (2.22.0)\n",
      "Requirement already satisfied: six in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from foursquare) (1.12.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests>=2.1->foursquare) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests>=2.1->foursquare) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests>=2.1->foursquare) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests>=2.1->foursquare) (2019.6.16)\n",
      "Building wheels for collected packages: foursquare\n",
      "  Building wheel for foursquare (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/50/82/db/97c078881efb89f4e89560487926fbadfff87a40e5fe41f6fb\n",
      "Successfully built foursquare\n",
      "Installing collected packages: foursquare\n",
      "Successfully installed foursquare-1!2019.2.16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install FourSquare client library\n",
    "!pip install foursquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fs_act.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a2ea852288f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfs_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fs_act.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfs_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fs_act.json'"
     ]
    }
   ],
   "source": [
    "fs_act = None\n",
    "with open('fs_act.json') as json_data:\n",
    "    fs_act = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs_act' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6fc4d8530be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfoursquare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_normalize\u001b[0m \u001b[0;31m# tranform JSON file into a pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfoursquare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFoursquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_act\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'client_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_secret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_act\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'client_secret'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fs_act' is not defined"
     ]
    }
   ],
   "source": [
    "import foursquare\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "fs = foursquare.Foursquare(client_id=fs_act['client_id'], client_secret=fs_act['client_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def venues_nearby(latitude, longitude, category, verbose=True):    \n",
    "    results = fs.venues.search(\n",
    "        params = {\n",
    "            'query': category, \n",
    "            'll': '{},{}'.format(latitude, longitude),\n",
    "            'radius': RADIUS,\n",
    "            'categoryId': fs_categories[category]\n",
    "        }\n",
    "    )    \n",
    "    df = json_normalize(results['venues'])\n",
    "    cols = ['Name','Latitude','Longitude','Tips','Users','Visits']    \n",
    "    if( len(df) == 0 ):        \n",
    "        df = pd.DataFrame(columns=cols)\n",
    "    else:        \n",
    "        df = df[['name','location.lat','location.lng','stats.tipCount','stats.usersCount','stats.visitsCount']]\n",
    "        df.columns = cols\n",
    "    if( verbose ):\n",
    "        print('{} \"{}\" venues are found within {}m of location'.format(len(df), category, RADIUS))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Find Metro Station around the cinema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_nearby(cinema['Latitude'], cinema['Longitude'], 'Metro Station').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Find Bus Stop around the cinema\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_nearby(cinema['Latitude'], cinema['Longitude'], 'Bus Stop').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find eating places around the cinema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_nearby(cinema['Latitude'], cinema['Longitude'], 'Food').head()\n",
    "venues_nearby(cinema['Latitude'], cinema['Longitude'], 'Arts & Entertainment').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With above data, I can use content-based recommendation technique to resolve the problem.\n",
    "\n",
    "Combine with FourSquare API which provides how many venues in different category of cinemas in New Delhi, a matrix which captured characteristic of venues nearby cinema are built. Stakeholder's favorite list is the profile to combine with the matrix to become a weighted matrix of favorite cinema.\n",
    "\n",
    "The weighted matrix can be applied on 5 target locations with venues information to generate a ranking result. The the top one on the ranking list can be recommended to the stakeholder.\n",
    "\n",
    "Before building the matrix, I have to prepare the required data and apply some data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = df_cinemas.duplicated('Address', keep=False)\n",
    "df_cinemas[duplicated].sort_values('Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cinemas.loc[29, 'Name'] = 'The Grand Cinema'\n",
    "\n",
    "\n",
    "df_cinemas.loc[44, 'Name'] = 'PVR Saket'\n",
    "df_cinemas.loc[45, 'Name'] = 'PVR Saket'\n",
    "\n",
    "df_cinemas.loc[42, 'Name'] = 'PVR MGF'\n",
    "\n",
    "\n",
    "df_cinemas.loc[43, 'Name'] = 'IMAX Saket'\n",
    "df_cinemas.loc[46, 'Name'] = 'IMAX Saket'\n",
    "\n",
    "df_cinemas.loc[1, 'Name'] = 'Emperor Cinemas - Entertainment Building'\n",
    "\n",
    "\n",
    "df_cinemas.loc[6, 'Name'] = 'Cinema City Noida'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cinemas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-14624f42b55c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_cinemas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_cinemas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cinemas' is not defined"
     ]
    }
   ],
   "source": [
    "df_cinemas[duplicated]\n",
    "\n",
    "df_cinemas.drop_duplicates('Address', inplace=True, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cinemas[df_cinemas.duplicated('Name')]\n",
    "\n",
    "df_cinemas.head()\n",
    "df_cinemas['ChiName'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cinemas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "venues_csv = Path('./cinemas_venues.csv')\n",
    "df_venues = None\n",
    "\n",
    "\n",
    "if( venues_csv.exists() ):\n",
    "    df_venues = pd.read_csv('./cinemas_venues.csv')\n",
    "else:    \n",
    "    \n",
    "    df_venues = pd.DataFrame(columns=['Cinema Name', 'Category', 'Name', 'Latitude', 'Longitude', 'Tips', 'Users', 'Visits'])\n",
    "    for (name, address, latitude, longitude) in df_cinemas.itertuples(index=False):\n",
    "        for cat, cat_id in fs_categories.items():\n",
    "            df = venues_nearby(latitude, longitude, cat, verbose=False)\n",
    "            df['Cinema Name'] = name\n",
    "            df['Category'] = cat\n",
    "            df_venues = df_venues.append(df, sort=True)\n",
    "    df_venues.to_csv('cinemas_venues.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total {} of venues are found'.format(len(df_venues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of venues in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues['Category'].value_counts().to_frame(name='Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues[(df_venues.Tips > 0)|(df_venues.Users > 0)|(df_venues.Visits > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues.drop(columns=['Tips','Users','Visits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues[df_venues.Category=='Nightlife Spot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues.drop(index=87, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comapred with other categories, only one 'Nightlife Spot' venue. This category is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_venues = pd.DataFrame(columns=['Location', 'Category', 'Name', 'Latitude', 'Longitude', 'Tips', 'Users', 'Visits'])\n",
    "for (location, address, latitude, longitude) in df_possible_locations.itertuples(index=False):\n",
    "    for cat, cat_id in fs_categories.items():\n",
    "        df = venues_nearby(latitude, longitude, cat, verbose=False)\n",
    "        df['Location'] = location\n",
    "        df['Category'] = cat\n",
    "        df_target_venues = df_target_venues.append(df, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_venues.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_venues[(df_target_venues.Tips > 0)|(df_target_venues.Users > 0)|(df_target_venues.Visits > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_venues.drop(columns=['Tips','Users','Visits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_venues['Category'].value_counts().to_frame(name='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues_count = df_venues.groupby(['Cinema Name','Category'], as_index=False).count()\n",
    "df_venues_count.drop(columns=['Latitude','Longitude'], inplace=True)\n",
    "df_venues_count.rename(columns={'Name':'Count'}, inplace=True)\n",
    "df_venues_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues_count = df_venues_count.pivot(index='Cinema Name', columns='Category', values='Count').fillna(0)\n",
    "df_venues_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the same process on target locations\n",
    "df_target_venues_count = df_target_venues.groupby(['Location','Category']).size().reset_index(name='Count')\n",
    "df_target_venues_count = df_target_venues_count.pivot(index='Location', columns='Category', values='Count').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_venues_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for boss's favorite cinema list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boss_favorite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check boss's favorite cinemas are inside the hong kong cinemas dataset\n",
    "\n",
    "Check the Hong Kong cinema list contains all stakeholder's favorite cinemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [ cinema['Name'] for cinema in boss_favorite ]\n",
    "df_cinemas[df_cinemas.Name.isin(names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Stakholder's favorite cinema list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boss_favorite = pd.DataFrame(boss_favorite, columns=['Name','Rating'])\n",
    "df_boss_favorite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.7.11\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs: \n",
      "    - seaborn=0.9\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openssl-1.1.1c             |       h7b6447c_1         3.8 MB\n",
      "    matplotlib-2.2.2           |   py36hb69df0a_2         6.6 MB\n",
      "    seaborn-0.9.0              |           py36_0         379 KB\n",
      "    sip-4.18.1                 |   py36hf484d3e_2         278 KB\n",
      "    qt-5.6.3                   |       h8bf5577_3        45.7 MB\n",
      "    pyqt-5.6.0                 |   py36h22d08a2_6         5.4 MB\n",
      "    certifi-2019.6.16          |           py36_1         156 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        62.3 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    certifi:    2019.6.16-py36_1      conda-forge --> 2019.6.16-py36_1     \n",
      "    openssl:    1.1.1c-h516909a_0     conda-forge --> 1.1.1c-h7b6447c_1    \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    matplotlib: 2.2.3-py37hb69df0a_0              --> 2.2.2-py36hb69df0a_2 \n",
      "    pyqt:       5.9.2-py37h05f1152_2              --> 5.6.0-py36h22d08a2_6 \n",
      "    qt:         5.9.6-h8703b6f_2                  --> 5.6.3-h8bf5577_3     \n",
      "    seaborn:    0.9.0-py_1            conda-forge --> 0.9.0-py36_0         \n",
      "    sip:        4.19.8-py37hf484d3e_0             --> 4.18.1-py36hf484d3e_2\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-1.1.1c       | 3.8 MB    | ##################################### | 100% \n",
      "matplotlib-2.2.2     | 6.6 MB    | ##################################### | 100% \n",
      "seaborn-0.9.0        | 379 KB    | ##################################### | 100% \n",
      "sip-4.18.1           | 278 KB    | ##################################### | 100% \n",
      "qt-5.6.3             | 45.7 MB   | ##################################### | 100% \n",
      "pyqt-5.6.0           | 5.4 MB    | ##################################### | 100% \n",
      "certifi-2019.6.16    | 156 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install seaborn=0.9 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/matplotlib/contour.py:25: MatplotlibDeprecationWarning: \n",
      "The mkdirs function was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "  import matplotlib.texmanager as texmanager\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute '_get_configdir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-64696823f4fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdedent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/site-packages/matplotlib/style/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreload_library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/site-packages/matplotlib/style/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mBASE_LIBRARY_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stylelib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Users may want multiple library paths, so store a list of paths.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mUSER_LIBRARY_PATHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_configdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stylelib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mSTYLE_EXTENSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mplstyle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mSTYLE_FILE_PATTERN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'([\\S]+).%s$'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mSTYLE_EXTENSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute '_get_configdir'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues_count.dtypes.to_frame(name='Data Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All datatype is numeric\n",
    "\n",
    "Generates descriptive statistics that summarize the central tendency, dispersion and shape of a dataset's distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cinema really has many 'Bus Stop', 'Food', 'Shop & Service' venues around. However it is unusual that a cinema has 4 metro stations nearby (within 500 meters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues_count['Metro Station'].value_counts().sort_index().to_frame('Cinema Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One cinema contains 4 Metro Stations around it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues_count[df_venues_count['Metro Station'] > 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_over_2 = df_venues_count[df_venues_count['Metro Station'] > 2].index.tolist()\n",
    "df_venues[(df_venues['Cinema Name'].isin(metro_over_2)) & (df_venues.Category == 'Metro Station')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-construct the dataframe again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_venues_count = df_venues.groupby(['Cinema Name','Category'], as_index=False).count()\n",
    "df_venues_count.drop(columns=['Latitude','Longitude'], inplace=True)\n",
    "df_venues_count.rename(columns={'Name':'Count'}, inplace=True)\n",
    "df_venues_count = df_venues_count.pivot(index='Cinema Name', columns='Category', values='Count').fillna(0)\n",
    "df_venues_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Plot the distribution of other variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "sns.distplot(df_venues_count['Arts & Entertainment'] , color=\"skyblue\", ax=axes[0, 0], kde=False)\n",
    "sns.distplot(df_venues_count['Bus Stop'] , color=\"olive\", ax=axes[0, 1], kde=False)\n",
    "sns.distplot(df_venues_count['Food'] , color=\"gold\", ax=axes[1, 0], kde=False)\n",
    "sns.distplot(df_venues_count['Shop & Service'] , color=\"teal\", ax=axes[1, 1], kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of other variables are quite similar. Now check their Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues_count.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that 'Bus Stop', 'Shop & Service' and 'Food' category are highly correlated.\n",
    "Find P-Value of the variables\n",
    "\n",
    "By convention, when the p-value is:\n",
    "\n",
    "< 0.001 we say there is strong evidence that the correlation is significant,\n",
    "\n",
    "< 0.05; there is moderate evidence that the correlation is significant,\n",
    "\n",
    "< 0.1; there is weak evidence that the correlation is significant, and\n",
    "\n",
    "is > 0.1; there is no evidence that the correlation is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_data = []\n",
    "for left in df_venues_count.columns:\n",
    "    p_values = [left]\n",
    "    for right in df_venues_count.columns:        \n",
    "        pearson_coef, p_value = stats.pearsonr(df_venues_count[left], df_venues_count[right])\n",
    "        if(p_value < 0.001):\n",
    "            p_values.append('strong')\n",
    "        elif(p_value < 0.05):\n",
    "            p_values.append('moderate')\n",
    "        elif(p_value < 0.1):\n",
    "            p_values.append('weak')\n",
    "        else:\n",
    "            p_values.append('no')            \n",
    "    p_value_data.append(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_values = pd.DataFrame(p_value_data, columns=['Category'] + df_venues_count.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The correlation between 'Bus Stop', 'Food', 'Metro Station' and 'Shop & Service' are statistically significant, and the coefficient of > 0.5 shows that the relationship is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boss_favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.7.11\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs: \n",
      "    - folium=0.5\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.6.16          |           py36_1         149 KB  conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    certifi: 2019.6.16-py36_1  --> 2019.6.16-py36_1  conda-forge\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    openssl: 1.1.1c-h7b6447c_1 --> 1.1.1c-h516909a_0 conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2019.6.16    | 149 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Folium installed and imported!\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge folium=0.5 --yes\n",
    "import folium\n",
    "\n",
    "print('Folium installed and imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del_coords = getLatLng('New Delhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the location of cinemas, target location and stakeholder's favorite cineams on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_map = folium.Map(location=del_coords, zoom_start=12, tiles='Stamen Toner')\n",
    "\n",
    "cinemas_fg = folium.FeatureGroup()\n",
    "targets_fg = folium.FeatureGroup()\n",
    "\n",
    "for(location, address, latitude, longitude) in df_possible_locations.itertuples(index=False):\n",
    "    targets_fg.add_child(\n",
    "        folium.features.CircleMarker(\n",
    "            location=(latitude, longitude),\n",
    "            popup=location,\n",
    "            radius=5,\n",
    "            fill=True,\n",
    "            color='yellow',\n",
    "            fill_opacity=1.\n",
    "        )\n",
    "    )\n",
    "\n",
    "boss_ratings = df_boss_favorite.set_index('Name')    \n",
    "name_list = boss_ratings.index.tolist()\n",
    "\n",
    "for (name, address, latitude, longitude ) in df_cinemas.itertuples(index=False):    \n",
    "    \n",
    "    color = 'blue'        \n",
    "    popup = name\n",
    "    \n",
    "    if( name in name_list ):\n",
    "        color = 'red'    \n",
    "        popup = '{} - Rating: {}'.format(name, boss_ratings.loc[name,'Rating'])\n",
    "        \n",
    "    cinemas_fg.add_child(        \n",
    "        folium.features.CircleMarker(\n",
    "            location=(latitude, longitude),\n",
    "            popup=popup,\n",
    "            radius=5,\n",
    "            fill=True,\n",
    "            color=color,\n",
    "            fill_opacity=1.\n",
    "        )\n",
    "    )\n",
    "    \n",
    "del_map.add_child(cinemas_fg)\n",
    "del_map.add_child(targets_fg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Most of New Delhi's cinemas (blue circle) and stakeholder's favorite cinemas (red circle) location are built near main road, and centralized in urban area of New Delhi. The target locations (yellow circle) of new cinema are not near to main road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning\n",
    "Now, let's use Content-Based or Item-Item recommendation systems. In this case, I am going to try to figure out the boss's favorite new cinema location by counting number of nearby venues and ratings given.\n",
    "\n",
    "Normalize the values of venues dataframe by using MinMaxScaler method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues_count.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "venues_normalized = scaler.fit_transform(df_venues_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_venues_normalized = pd.DataFrame(\n",
    "    venues_normalized,\n",
    "    index=df_venues_count.index,\n",
    "    columns=df_venues_count.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the data with boss's favorite list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boss_rating_table = pd.merge(\n",
    "    df_boss_favorite,\n",
    "    df_venues_normalized,\n",
    "    how='inner',\n",
    "    left_on='Name',\n",
    "    right_index=True\n",
    ")\n",
    "boss_rating_table.drop(['Name','Rating'], axis=1, inplace=True)\n",
    "boss_rating_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product to get the weight of rating on each category according to boss's favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boss_profile = boss_rating_table.transpose().dot(df_boss_favorite['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boss_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the values of target venues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_normalized = pd.DataFrame(\n",
    "    scaler.transform(df_target_venues_count),\n",
    "    index=df_target_venues_count.index,\n",
    "    columns=df_target_venues_count.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the boss's profile and the complete list of cinemas and their venues count in hand, I am going to take the weighted average of every lcoation based on the profile and recommend the top location that most satisfy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommend = (df_targets_normalized*boss_profile).sum(axis=1)/boss_profile.sum()\n",
    "df_recommend = df_recommend.reset_index(name='Rating')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_possible_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(\n",
    "    df_possible_locations,\n",
    "    df_recommend,\n",
    "    left_on='Location',\n",
    "    right_on='Location'\n",
    ")\n",
    "df_final.sort_values('Rating', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('I should recommend the location \"{}\" of address \"{}\" to the stackholder'.format(df_final.iat[0,0], df_final.iat[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is reasonable. Location \"L5\" has the most number of venues in category \"Bus Stop\", \"Food\", \"Metro Station\" and \"Shop & Service\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_venues_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, these categories are most concerned by the stakeholder according to profile rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boss_profile.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Therefore, Location \"L5\" should be recommeded to the stakeholder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion¶\n",
    "Discussion section where you discuss any observations you noted and any recommendations you can make based on the results.\n",
    "\n",
    "Number of venues of 5 target locations are actually below the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
